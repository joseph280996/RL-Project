@book{sutton1998reinforcement,
  title={Reinforcement Learning: An Introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press Cambridge}
}

@article{riedmiller2009reinforcement,
  title={Reinforcement learning for robot soccer},
  author={Riedmiller, Martin and Gabel, Thomas and Hafner, Roland and Lange, Sascha},
  journal={Autonomous Robots},
  volume={27},
  number={1},
  pages={55--73},
  year={2009},
  publisher={Springer}
}


@article{stone2005reinforcement,
  title={Reinforcement learning for robocup soccer keepaway},
  author={Stone, Peter and Sutton, Richard S and Kuhlmann, Gregory},
  journal={Adaptive Behavior},
  volume={13},
  number={3},
  pages={165--188},
  year={2005},
  publisher={Sage Publications Sage CA: Thousand Oaks, CA}
}


@book{thrun2005probabilistic,
  title={Probabilistic robotics},
  author={Thrun, Sebastian and Burgard, Wolfram and Fox, Dieter},
  year={2005},
  publisher={MIT press}
}

@inproceedings{short2010no,
  title={No fair!! an interaction with a cheating robot},
  author={Short, Elaine and Hart, Justin and Vu, Michelle and Scassellati, Brian},
  booktitle={2010 5th ACM/IEEE International Conference on Human-Robot Interaction (HRI)},
  pages={219--226},
  year={2010},
  organization={IEEE}
}

@misc{huggingface_dql,
    title = {The Deep Q-Learning Algorithm},
    author = {Hugging Face},
    year = {2023},
    howpublished = {\url{https://huggingface.co/learn/deep-rl-course/unit3/deep-q-learning}},
    note = {Hugging Face Deep RL Course},
    url = {https://huggingface.co/learn/deep-rl-course/unit3/deep-q-learning}
}
@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@inproceedings{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={1861--1870},
  year={2018},
  organization={PMLR}
}

@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

@inproceedings{liniger2015optimization,
  title={Optimization-based autonomous racing of 1: 43 scale RC cars},
  author={Liniger, Alexander and Lygeros, John and Apkarian, Pierre},
  booktitle={2015 European Control Conference (ECC)},
  pages={586--591},
  year={2015},
  organization={IEEE}
}

@article{saxena2020driving,
  title={Driving in the matrix: Can virtual worlds replace human-generated annotations for real world tasks?},
  author={Saxena, Abhinav and Isola, Phillip and others},
  journal={arXiv preprint arXiv:2004.06477},
  year={2020}
}

@inproceedings{wurman2002racing,
  title={Racing against opponents with approximate predictive state representations},
  author={Wurman, Peter R and D'Andrea, Raffaello and Mountz, Mick},
  booktitle={Proceedings of the National Conference on Artificial Intelligence},
  pages={523--528},
  year={2002},
  organization={Citeseer}
}

@misc{rocketmeister2020,
  author = {Brummerloh, Daniel},
  title = {RocketMeister},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/danuo/rocket-meister/}}
}

@book{brouillard2016perfectcorner,
  author    = {Adam Brouillard},
  title     = {The Perfect Corner: A Driver's Step-By-Step Guide to Finding Their Own Optimal Line Through the Physics of Racing},
  year      = {2016},
  month     = {March},
  day       = {18},
  publisher = {Paradigm Shift Motorsport Books},
  isbn      = {9780997382426},
  address   = {Paradigm Shift Driver Development}
}

@inproceedings{van2016deep,
  title={Deep reinforcement learning with double Q-learning},
  author={Van Hasselt, Hado and Guez, Arthur and Silver, David},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={30},
  year={2016}
}

@article{kendall2018drive,
  title={Learning to drive in a day},
  author={Kendall, Alex and Hawke, Jamie and Janz, David and Mazur, Pawel and Reda, Daniele and Allen, John-Paul and Lam, Victor-Daniel and Bewley, Alex and Shah, Amar},
  journal={arXiv preprint arXiv:1807.00412},
  year={2018}
}

@misc{towardsdatascience_dqn,
  author       = {Jonathan Hui},
  title        = {Reinforcement Learning Explained Visually - Part 5: Deep Q-Networks Step by Step},
  year         = {2018},
  url          = {https://towardsdatascience.com/reinforcement-learning-explained-visually-part-5-deep-q-networks-step-by-step-5a5317197f4b},
  note         = {Accessed: 2024-12-18}
}

@inproceedings{okelly2020f1tenth,
  title={F1TENTH: An Open-source Evaluation Environment for Continuous Control and Reinforcement Learning},
  author={Oâ€™Kelly, Matthew and Zheng, Hongrui and Karthik, Dhruv and Mangharam, Rahul},
  booktitle={NeurIPS 2019 Competition and Demonstration Track},
  pages={77--89},
  year={2020},
  organization={PMLR}
}

@inproceedings{van2010double,
  title={Double Q-learning},
  author={van Hasselt, Hado},
  booktitle={Advances in Neural Information Processing Systems},
  volume={23},
  year={2010}
}

@phdthesis{watkins1989learning,
  title={Learning from Delayed Rewards},
  author={Watkins, Christopher JCH},
  year={1989},
  school={King's College, Cambridge},
  type={PhD Thesis}
}

